{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source you are drawing inspiration from: https://www.dataquest.io/mission/75/improving-your-submission\n",
    "Any additional ideas of your own that you are incorporating: If time permits, I would like to see how many of the captains and other crew members survived. Also, the effect of that info to our kaggle score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading Datasets\n",
    "import pandas as pd\n",
    "titanic = pd.read_csv('train.csv')\n",
    "titanic_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Because the cleanup is used on a lot of csv's\n",
    "def csv_cleanup(csv):\n",
    "    #Filling missing data with the most common one in that dataset\n",
    "    csv.Age = csv.Age.fillna(csv.Age.median())\n",
    "    csv.Fare = csv.Fare.fillna(csv.Fare.median())\n",
    "    #Setting survey results like male/female/s/c/q with numbers for better calculation\n",
    "    csv.loc[csv.Sex == \"female\", \"Sex\"] = 1\n",
    "    csv.loc[csv.Sex == \"male\", \"Sex\"] = 0\n",
    "    csv.Embarked = csv.Embarked.fillna(\"S\")\n",
    "    csv.loc[csv.Embarked == \"S\", \"Embarked\"] = 0\n",
    "    csv.loc[csv.Embarked == \"C\", \"Embarked\"] = 1\n",
    "    csv.loc[csv.Embarked == \"Q\", \"Embarked\"] = 2\n",
    "    return csv\n",
    "    \n",
    "titanic = csv_cleanup(titanic)\n",
    "titanic_test = csv_cleanup(titanic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following the Dataquest Random Tree tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random trees are basically columns split into sections/branches of trees. It is uaually helpful to use this method when the data is not linear. For example, Fare and Survival might not have an exact linear relation, i.e. Survival increasing with Fare. One problem with Random Trees is that it can easily overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800224466891\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make\n",
    "# min_samples_split is the minimum number of rows we need to make a split\n",
    "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are changing parameters to make the algorithm more accurate. Because it is easy to overfit the data, having many branches is very helpful. What is does is making sure the score we get using averages of many predictions will improve in accuracy by using lots of branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819304152637\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the algorithm using all the training data\n",
    "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Make predictions using the test set.\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"kagglea1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.75120 Kaggle Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the family size column. I have been trying to use this data to find something significant in the dataset. It would be interesting to see what this does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Col           2\n",
      "Major         2\n",
      "Mlle          2\n",
      "Countess      1\n",
      "Ms            1\n",
      "Lady          1\n",
      "Jonkheer      1\n",
      "Don           1\n",
      "Mme           1\n",
      "Capt          1\n",
      "Sir           1\n",
      "dtype: int64\n",
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Generating a familysize column\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "\n",
    "# The .apply method generates a new series\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "import re\n",
    "\n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "print(pd.value_counts(titles))\n",
    "\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "# Verify that we converted everything.\n",
    "print(pd.value_counts(titles))\n",
    "\n",
    "# Add in the title column.\n",
    "titanic[\"Title\"] = titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, I talked about looking for the titles liek capt. etc to see how they survived. Not sure if that is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1      800\n",
      " 14       8\n",
      " 149      7\n",
      " 63       6\n",
      " 50       6\n",
      " 59       6\n",
      " 17       5\n",
      " 384      4\n",
      " 27       4\n",
      " 25       4\n",
      " 162      4\n",
      " 8        4\n",
      " 84       4\n",
      " 340      4\n",
      " 43       3\n",
      " 269      3\n",
      " 58       3\n",
      " 633      2\n",
      " 167      2\n",
      " 280      2\n",
      " 510      2\n",
      " 90       2\n",
      " 83       1\n",
      " 625      1\n",
      " 376      1\n",
      " 449      1\n",
      " 498      1\n",
      " 588      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "# A dictionary mapping family name to id\n",
    "family_id_mapping = {}\n",
    "\n",
    "# A function to get the id given a row\n",
    "def get_family_id(row):\n",
    "    # Find the last name by splitting on a comma\n",
    "    last_name = row[\"Name\"].split(\",\")[0]\n",
    "    # Create the family id\n",
    "    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n",
    "    # Look up the id in the mapping\n",
    "    if family_id not in family_id_mapping:\n",
    "        if len(family_id_mapping) == 0:\n",
    "            current_id = 1\n",
    "        else:\n",
    "            # Get the maximum id from the mapping and add one to it if we don't have an id\n",
    "            current_id = (max(family_id_mapping.items(), key=operator.itemgetter(1))[1] + 1)\n",
    "        family_id_mapping[family_id] = current_id\n",
    "    return family_id_mapping[family_id]\n",
    "\n",
    "# Get the family ids with the apply method\n",
    "family_ids = titanic.apply(get_family_id, axis=1)\n",
    "\n",
    "# There are a lot of family ids, so we'll compress all of the families under 3 members into one code.\n",
    "family_ids[titanic[\"FamilySize\"] < 3] = -1\n",
    "\n",
    "# Print the count of each unique id.\n",
    "print(pd.value_counts(family_ids))\n",
    "\n",
    "titanic[\"FamilyId\"] = family_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAEpCAYAAAC3ChhmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNL/8P5+hlrVBKYk1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c2888ded0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811447811448\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "# Pick only the four best features.\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "# Compute the accuracy score for all the cross validation folds\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "\n",
    "# Take the mean of the scores\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.278338945006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "import numpy as np\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold.  \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This score is pretty low in comparison to the one in the tutorial. I had to change it to pandas series. So not sure why this is effecting the printed accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the testing data set in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "7       2\n",
      "6       2\n",
      "10      1\n",
      "5       1\n",
      "dtype: int64\n",
      "{\"O'Sullivan0\": 426, 'Mangan0': 620, 'Lindqvist1': 543, 'Denkoff0': 297, 'Rouse0': 413, 'Berglund0': 207, 'Meo0': 142, 'Arnold-Franchi1': 49, 'Chronopoulos1': 71, 'Skoog5': 63, 'Widener2': 329, 'Pengelly0': 217, 'Goncalves0': 400, 'Myhrman0': 626, 'Beane1': 456, 'Moss0': 104, 'Carlsson0': 610, 'Nicholls2': 136, 'Jussila1': 110, 'Jussila0': 483, 'Long0': 632, 'Wheadon0': 33, 'Connolly0': 261, 'Hansen2': 680, 'Stephenson1': 493, 'Davies0': 336, 'Silven2': 359, 'Vanden Steen0': 311, 'Astor1': 571, 'Patchett0': 480, 'Johanson0': 184, 'Coleridge0': 220, 'Christmann0': 87, 'Carter3': 340, 'Compton2': 665, 'Carter1': 226, 'Turkula0': 414, 'Hassab0': 558, 'Saad0': 566, 'Mellors0': 208, 'Mamee0': 36, 'Madsen0': 119, 'Anderson0': 395, 'Kraeff0': 42, 'Robbins0': 468, 'Lundahl0': 522, 'Gilinski0': 490, 'Porter0': 107, 'Sdycoff0': 352, 'Green0': 204, 'Bishop1': 263, 'Sinkkonen0': 603, 'Otter0': 640, 'Dahl0': 299, 'Troutt0': 582, 'Samaan2': 48, 'Edvardsson0': 553, 'Petroff0': 98, 'Burke0': 134, 'Cardeza1': 556, 'Hawksford0': 599, 'Somerton0': 416, 'Healy0': 248, 'Andersson0': 137, 'Fortune5': 27, 'Andersson6': 14, 'Johnson2': 9, 'Johnson0': 273, 'Coxon0': 91, 'Banfield0': 696, 'McCarthy0': 7, 'Panula5': 50, 'West3': 58, 'Kallio0': 374, 'Hoyt1': 206, 'Hoyt0': 638, 'Mannion0': 589, 'Touma2': 232, 'Futrelle1': 4, 'Jardin0': 507, 'Lemore0': 437, 'Davies2': 460, 'Robert1': 630, 'Butt0': 451, 'Wick2': 286, 'Emanuel0': 628, 'Ibrahim Shawah0': 643, 'Carbines0': 175, 'McEvoy0': 583, 'Moutal0': 75, 'Ling0': 157, 'Watson0': 552, 'Lahoud0': 443, 'Sedgwick0': 302, 'Beesley0': 22, 'Sheerlinck0': 79, 'Hunt0': 218, 'Clifford0': 408, 'Stranden0': 602, 'Ahlin1': 40, 'Woolner0': 55, 'Caram1': 482, 'Sandstrom2': 11, 'Nakid2': 333, 'Frost0': 412, 'Moen0': 73, 'Henry0': 239, 'Persson1': 241, 'Mudd0': 671, 'Glynn0': 32, 'Bowerman1': 312, 'Daniel0': 505, 'Nysten0': 132, 'Saalfeld0': 270, 'Turcin0': 173, 'Nasser1': 10, 'Waelens0': 78, 'Homer0': 502, 'Graham1': 242, 'Graham0': 699, 'Brown0': 177, 'Dorking0': 256, 'Bing0': 72, 'Blank0': 191, 'Tornquist0': 245, 'Olsen1': 180, 'Olsen0': 144, 'Davison1': 304, 'Butler0': 544, 'Calderhead0': 575, 'Cor0': 530, 'Kalvik0': 534, 'Hagland1': 386, 'Boulos2': 131, 'Boulos0': 497, 'Leitch0': 496, 'Endres0': 581, 'Fleming0': 275, 'Natsch1': 247, 'Garfirth0': 614, 'Blackwell0': 300, 'Thayer2': 461, 'Holm0': 657, 'Rekic0': 105, 'Allen0': 5, 'Hendekovic0': 282, 'Svensson0': 424, 'Montvila0': 698, 'Perreault0': 441, 'Francatelli0': 278, 'Gronnestad0': 621, 'Maisner0': 399, 'Radeff0': 537, 'Daly0': 432, 'Jarvis0': 488, 'Bowen0': 515, 'Risien0': 453, 'Walker0': 436, 'Klaber0': 578, 'Wright0': 466, 'Artagaveytia0': 419, 'Navratil2': 138, 'Hays2': 658, 'Seward0': 383, 'Hays0': 279, 'Appleton2': 478, 'Fry0': 654, 'Romaine0': 171, 'de Messemaeker1': 469, 'Gustafsson0': 331, 'Gustafsson2': 101, 'Lulic0': 659, 'Beckwith2': 225, 'Sutton0': 516, 'Cunningham0': 355, 'Behr0': 700, 'Rothschild1': 434, 'Stankovic0': 257, 'Abelson1': 277, 'Lobb1': 230, 'Shellard0': 423, 'Knight0': 593, 'Silverthorne0': 572, \"O'Leary0\": 535, 'Saundercock0': 13, 'Baxter1': 114, 'Elias0': 624, 'Nankoff0': 598, 'Mitkoff0': 533, 'Lines1': 677, 'Burns0': 298, \"O'Driscoll0\": 47, 'Cumings1': 2, 'Culumovic0': 674, 'Penasco y Castellana1': 276, 'Parkes0': 251, 'Duff Gordon1': 467, 'Sloper0': 24, 'Strom2': 228, 'Ringhini0': 327, 'Barah0': 616, 'Richards2': 350, 'Crease0': 67, 'Cavendish1': 600, 'Bjornstrom-Steffansson0': 371, 'Masselmani0': 20, 'Moubarek2': 65, 'Turja0': 555, 'Goldsmith2': 154, 'Fahlstrom0': 210, 'Holverson1': 35, 'Herman3': 510, 'Nenkoff0': 205, 'Nysveen0': 292, 'Eklund0': 617, 'Paulner0': 487, 'Nilsson0': 284, 'Dick1': 563, 'Dantcheff0': 639, 'Swift0': 682, 'Humblen0': 570, 'McCormack0': 661, 'Duane0': 253, 'Ekstrom0': 121, 'Wiseman0': 366, 'Smith0': 160, 'Marvin1': 604, 'Cleaver0': 576, 'Gill0': 683, 'Cameron0': 193, 'Augustsson0': 663, 'Petranec0': 97, 'Stahelin-Maeglin0': 523, 'McDermott0': 80, 'Dean3': 90, 'Laleff0': 691, 'Meyer0': 649, 'Meyer1': 34, 'Johansson0': 100, 'Cacic0': 405, 'Ryerson4': 280, 'Becker3': 167, 'Tobin0': 627, 'Murphy1': 219, 'Goldschmidt0': 93, 'Kink2': 68, 'Weisz1': 125, 'Hold1': 215, 'Stanley0': 420, 'Minahan2': 222, 'Toufik0': 450, 'Minahan1': 354, 'Olsvigen0': 559, 'Odahl0': 307, 'Coleff0': 435, 'Vestrom0': 15, 'Hood0': 70, 'Yousseff0': 421, 'Barton0': 109, 'Icard0': 61, 'Smiljanic0': 148, 'Harmer0': 634, 'Ford4': 84, 'Maioni0': 428, 'Abbing0': 675, 'Oreskovic0': 347, 'Sundman0': 356, 'Kink-Heilmann2': 168, 'Lehmann0': 339, 'Dennis0': 288, 'del Carlo1': 316, 'Najib0': 690, 'Ohman0': 465, 'McCoy2': 272, 'Osen0': 129, 'Pernot0': 166, 'Kent0': 415, 'Turpin1': 41, 'Zabour1': 108, 'Alexander0': 650, 'Palsson4': 8, 'Hogeboom1': 618, 'Keefe0': 404, 'Eustis1': 422, 'Marechal0': 669, 'Uruchurtu0': 30, 'Downton0': 485, 'Ilmakangas1': 591, 'Corn0': 147, 'Parrish1': 236, 'Jerwan0': 406, 'Aks1': 678, 'Lam0': 565, 'Slayter0': 290, 'Weir0': 567, 'Frolicher2': 454, 'Danbom2': 365, 'Alhomaki0': 670, 'Brown2': 548, 'Faunthorpe1': 53, 'Givard0': 195, 'Leyson0': 213, 'Potter1': 692, 'Emir0': 26, 'Slocovski0': 85, 'Celotti0': 86, 'Rood0': 169, 'Betros0': 330, 'Larsson0': 211, 'Andreasson0': 88, 'Vande Walle0': 183, 'Morley0': 396, 'Trout0': 344, 'Thorneycroft1': 372, 'Shorney0': 92, 'Attalah0': 111, 'Ward0': 235, 'Yousif0': 310, 'Wiklund1': 325, 'Thorne0': 233, 'Warren1': 320, 'Milling0': 398, 'Rommetvedt0': 545, 'Pickard0': 370, 'Hassan0': 592, 'Heininen0': 655, 'Bazzani0': 200, 'Plotcharsky0': 335, 'Lindell1': 503, 'Caldwell2': 76, 'Meanwell0': 474, 'Bystrom0': 684, 'Harrison0': 238, 'Goldenberg1': 388, 'Webber0': 117, 'Shelley1': 693, 'Mayne0': 577, 'Honkanen0': 198, 'Karlsson0': 410, 'Calic0': 153, 'Eitemiller0': 538, 'Chapman0': 568, 'Asplund6': 25, 'Peuchen0': 385, 'Cairns0': 244, 'Bailey0': 611, 'Hanna0': 268, 'Garside0': 481, 'Mernagh0': 179, 'Staneff0': 74, 'Toomey0': 393, 'Canavan0': 425, 'Dakic0': 560, 'Foo0': 529, 'Pasic0': 666, 'Novel0': 57, 'Lemberopolous0': 673, 'Hocking4': 625, 'Moran1': 106, 'Abbott2': 252, 'Kvillner0': 377, 'Elias2': 309, 'Doharr0': 476, 'Norman0': 472, 'Leader0': 641, 'Smart0': 402, 'White1': 99, 'Gale1': 348, 'Doling1': 95, 'Moor1': 607, 'Taussig2': 237, 'Pinsky0': 174, 'Gallagher0': 573, 'Markun0': 694, 'de Mulder0': 258, 'Kassem0': 444, 'Yrois0': 182, 'Kantor1': 96, 'Sobey0': 126, 'Shutes0': 506, 'Brocklebank0': 509, 'Cherry0': 234, 'Dooley0': 701, 'Hedman0': 646, 'Madigan0': 181, 'Parr0': 524, 'Campbell0': 401, 'Mullens0': 569, 'Charters0': 363, 'Jonsson0': 477, 'Ostby1': 54, 'Wilhelms0': 551, 'Williams1': 145, 'Williams0': 18, 'Maenpaa0': 221, 'Stone0': 662, 'Lennon1': 46, 'Olsson0': 254, 'Harknett0': 214, 'Horgan0': 508, 'Hart0': 353, 'Hart2': 283, 'Ilett0': 82, 'Baumann0': 156, 'Youseff0': 185, 'Reeves0': 240, 'Thomas1': 645, 'Jensen0': 527, 'Jensen1': 584, 'Cribb1': 150, 'Ross0': 486, 'Andersen-Jensen1': 176, 'Gilnagh0': 146, 'Moran0': 6, 'Coelho0': 123, 'Razi0': 679, 'Reuchlin0': 660, 'Kiernan1': 196, 'Partner0': 295, 'Jermyn0': 322, 'Salkjelsvik0': 103, 'Lahtinen2': 281, 'Drew2': 358, 'Hosono0': 260, 'Danoff0': 289, 'van Billiard2': 143, 'Bracken0': 203, 'Coutts2': 305, 'Connors0': 113, 'Jenkin0': 69, 'Hodges0': 586, 'Vovk0': 442, 'Backstrom1': 188, 'Devaney0': 44, 'Backstrom3': 83, 'Barbara1': 317, \"O'Connell0\": 520, 'Vande Velde0': 608, 'Reynaldo0': 380, 'Isham0': 163, \"O'Brien0\": 463, \"O'Brien1\": 170, 'Giglio0': 130, 'Ponesell0': 644, 'Nicola-Yarred1': 39, 'Angle1': 439, 'Mellinger1': 246, 'Newell1': 197, 'Lang0': 431, 'Davidson1': 549, 'Richard0': 127, 'Ball0': 293, 'Drazenoic0': 122, 'Robins1': 124, 'Richards5': 376, 'Nosworthy0': 51, 'Moore0': 116, 'Newsom2': 128, 'Sjoblom0': 635, 'Zimmerman0': 364, 'Kenyon1': 392, 'Fynney0': 21, 'Laroche3': 43, 'Renouf1': 409, 'Silvey1': 375, 'Christy2': 484, 'Renouf3': 588, 'Theobald0': 612, 'Pekoniemi0': 112, 'Bateman0': 140, 'Spencer1': 31, 'Allison3': 269, 'Cohen0': 186, 'Dimic0': 306, 'Bourke2': 172, 'Farthing0': 447, 'Hamalainen2': 224, 'Karaic0': 504, 'Pettersson0': 648, 'Landergren0': 328, 'Willey0': 532, 'Braund1': 1, 'Slemen0': 652, 'Jalsevac0': 390, 'Harder1': 324, 'Elsbury0': 494, 'Carrau0': 81, 'Sutehall0': 697, 'Sawyer0': 554, 'Vander Planke1': 19, 'Peters0': 557, 'Vander Planke2': 38, 'Dahlberg0': 695, 'Sharp0': 462, 'Sirota0': 667, 'Barkworth0': 521, 'Mack0': 623, 'Sjostedt0': 212, 'Slabenoff0': 499, 'Dodge2': 382, 'Mineff0': 266, 'Hocking3': 449, 'Hickman2': 115, 'Perkin0': 194, 'Stewart0': 64, 'Giles1': 681, 'Lindblom0': 250, 'Meek0': 357, 'Morrow0': 470, 'Newell2': 539, 'Beavan0': 326, 'Balkic0': 688, 'van Melkebeke0': 687, 'Foreman0': 387, 'Hampe0': 378, 'Birkeland0': 351, 'Mockler0': 315, 'Millet0': 391, 'Peter2': 120, 'Yasbeck1': 512, 'Osman0': 642, 'Buss0': 337, 'Sunderland0': 202, 'Lefebre4': 162, 'Bryhl1': 590, 'McGovern0': 314, 'Nye0': 66, 'Davis0': 525, 'Aubart0': 323, 'Spedden2': 287, 'Harris0': 201, 'Harris1': 62, 'McGough0': 433, 'Hewlett0': 16, 'Cann0': 37, 'Mallet2': 656, 'Kirkland0': 517, 'Ridsdale0': 446, 'Connaghton0': 605, 'Stoytcheff0': 475, 'Hippach1': 294, 'Dowdell0': 77, 'Klasen2': 161, 'Rothes0': 613, \"O'Connor0\": 394, 'Ivanoff0': 597, 'Clarke1': 367, 'Scanlan0': 403, 'Troupiansky0': 595, 'Reed0': 227, 'Rintamaki0': 492, 'Chambers1': 587, 'Haas0': 265, 'Greenfield1': 94, 'Jansson0': 341, 'Gheorgheff0': 362, 'Mitchell0': 550, 'Bonnell0': 12, 'Murdlin0': 491, 'Lester0': 651, 'Van Impe2': 361, 'Simonius-Blumer0': 531, 'Torber0': 501, 'Gillespie0': 585, 'Naidenoff0': 259, 'McNamee1': 601, 'de Pelsmaeker0': 255, 'Quick2': 429, 'Byles0': 139, 'Sage10': 149, 'Frolicher-Stehli2': 489, 'Peduzzi0': 389, 'Chibnall1': 155, 'Hakkarainen1': 133, 'Watt0': 151, 'Sirayanian0': 60, 'Leonard0': 165, 'Bissette0': 243, 'Adahl0': 319, 'LeRoy0': 452, 'Tomlin0': 653, 'Kimball1': 513, 'Gavey0': 511, 'Mionoff0': 102, 'Farrell0': 445, 'Goodwin7': 59, 'Strom1': 187, 'Ali0': 192, 'Funk0': 313, 'Van der hoef0': 158, 'Roebling0': 686, 'Simmons0': 473, 'Asim0': 318, 'Rosblom2': 231, 'Lovell0': 209, 'Phillips0': 368, 'Leinonen0': 526, 'Markoff0': 676, 'Levy0': 264, 'Frauenthal2': 540, 'Frauenthal1': 296, 'Baclini3': 384, 'Johannesen-Bratthammer0': 381, 'Jonkoff0': 609, 'Williams-Lambert0': 308, 'Serepeca0': 672, 'Longley0': 518, \"O'Dwyer0\": 28, 'Kelly0': 271, 'Douglas1': 457, 'Crosby2': 455, 'Niskanen0': 345, 'Collander0': 301, 'Gee0': 397, 'Tikkanen0': 334, 'McKane0': 342, 'Molson0': 418, 'Bostandyeff0': 519, 'Ayoub0': 631, 'Rogers0': 45, 'Chip0': 668, 'Cook0': 546, 'Stead0': 229, 'Soholt0': 580, 'Moraweck0': 285, 'Bidois0': 332, 'Taylor1': 547, 'Bradley0': 430, 'Fischer0': 561, 'Barber0': 262, 'Albimona0': 189, 'Hale0': 164, 'Flynn0': 369, 'Sadlier0': 338, 'Keane0': 274, 'Young0': 291, 'Lindahl0': 223, 'Rugg0': 56, 'Johnston3': 633, 'Petterson1': 379, 'Pavlovic0': 440, 'Sivic0': 471, 'Hirvonen1': 411, 'Allum0': 664, 'Harrington0': 500, 'Windelov0': 417, 'Lesurer0': 596, 'Pain0': 343, 'Lievens0': 622, 'Fox0': 303, 'Lewy0': 267, 'McMahon0': 118, 'Greenberg0': 579, 'Heikkinen0': 3, 'Louch1': 373, 'Chapman1': 495, 'Berriman0': 594, 'Moussa0': 321, 'Ryan0': 438, 'Madill1': 562, 'Duran y More1': 685, 'Bengtsson0': 152, 'Harper1': 52, 'Kilgannon0': 629, 'Badt0': 541, 'Salonen0': 448, 'Guggenheim0': 636, 'Widegren0': 349, 'Brewe0': 619, 'Sivola0': 159, 'Nirva0': 615, 'Rice5': 17, 'Andrews0': 647, 'Andrews1': 249, 'Collyer2': 216, 'Strandberg0': 407, 'Colley0': 542, 'Nicholson0': 458, 'Chaffee1': 89, 'Gaskell0': 637, 'Wells2': 606, 'Leeni0': 464, 'Todoroff0': 29, 'Adams0': 346, 'Pears1': 141, 'Sagesser0': 528, 'Carr0': 190, 'McGowan0': 23, 'Hansen0': 514, 'Hansen1': 574, 'Karun1': 564, 'Rush0': 479, 'Matthews0': 360, 'Laitinen0': 427, 'Padro y Manent0': 459, 'Andrew0': 135, 'Vander Cruyssen0': 689, 'Jacobsohn1': 199, 'Lurette0': 178, 'Jacobsohn3': 498, 'Hegarty0': 536}\n"
     ]
    }
   ],
   "source": [
    "# First, we'll add titles to the test set.\n",
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "# We're adding the Dona title to the mapping, because it's in the test set, but not the training set\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "titanic_test[\"Title\"] = titles\n",
    "# Check the counts of each unique title.\n",
    "print(pd.value_counts(titanic_test[\"Title\"]))\n",
    "\n",
    "# Now, we add the family size column.\n",
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
    "\n",
    "print(family_id_mapping)\n",
    "family_ids = titanic_test.apply(get_family_id, axis=1)\n",
    "family_ids[titanic_test[\"FamilySize\"] < 3] = -1\n",
    "titanic_test[\"FamilyId\"] = family_ids\n",
    "titanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "\n",
    "predictions[predictions <= .5] = 0\n",
    "predictions[predictions > .5] = 1\n",
    "predictions = predictions.astype(int)\n",
    "full_predictions.append(predictions)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv(\"kagglea2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Score of 0.79904"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future Improvements: I would like to explore more by looking for other family members using the last name of people and comparing it to the number of family members they have on board. This can help in checking how accurate the Family_Size is in predictions. We can also look at the composition of the family. Compare that to Pclass + Sex. Or even Age (Child/Youth/Adult/Old) + gender.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update:\n",
    "Adding Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "import numpy as np\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]],\n",
    "    [RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2), [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold.  \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "predictions = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "7       2\n",
      "6       2\n",
      "10      1\n",
      "5       1\n",
      "dtype: int64\n",
      "{\"O'Sullivan0\": 426, 'Mangan0': 620, 'Lindqvist1': 543, 'Denkoff0': 297, 'Sincock0': 813, 'Rouse0': 413, 'Berglund0': 207, 'Meo0': 142, 'Arnold-Franchi1': 49, 'Chronopoulos1': 71, 'Skoog5': 63, 'Walcroft0': 897, 'Widener2': 329, 'Pengelly0': 217, 'Goncalves0': 400, 'Andersen0': 829, 'Myhrman0': 626, 'Beane1': 456, 'Moss0': 104, 'Carlsson0': 610, 'Nicholls2': 136, 'Jussila1': 110, 'Jussila0': 483, 'Peltomaki0': 725, 'Long0': 632, 'Cassebeer0': 809, 'Portaluppi0': 858, 'Wheadon0': 33, 'Connolly0': 261, 'Hansen2': 680, 'Stephenson1': 493, 'Howard0': 862, 'Smyth0': 805, 'Davies0': 336, 'Silven2': 359, 'Vanden Steen0': 311, 'Sadowitz0': 878, 'Astor1': 571, 'Patchett0': 480, 'Denbury0': 891, 'Johanson0': 184, 'Coleridge0': 220, 'Christmann0': 87, 'Carter3': 340, 'Compton2': 665, 'Carter1': 226, 'Turkula0': 414, 'Lindeberg-Lind0': 793, 'Hassab0': 558, 'Badman0': 755, 'Aronsson0': 914, 'Saad0': 566, 'Mellors0': 208, 'Mamee0': 36, 'Dika0': 734, 'Madsen0': 119, 'Bird0': 801, 'Anderson0': 395, 'Kraeff0': 42, 'Robbins0': 468, 'Lundahl0': 522, 'Gilinski0': 490, 'Porter0': 107, 'Sdycoff0': 352, 'Green0': 204, 'Bishop1': 263, 'Sinkkonen0': 603, 'Otter0': 640, 'Dahl0': 299, 'Troutt0': 582, 'Samaan2': 48, 'Vartanian0': 877, 'Edvardsson0': 553, 'Larsson-Rondberg0': 920, 'Angheloff0': 874, 'Petroff0': 98, 'Burke0': 134, 'Cardeza1': 556, 'Hawksford0': 599, 'Somerton0': 416, 'Healy0': 248, 'Andersson0': 137, 'Fortune5': 27, 'Andersson6': 14, 'Willard0': 842, 'Johnson2': 9, 'Johnson0': 273, 'Wheeler0': 913, 'Coxon0': 91, 'Banfield0': 696, 'Wilkes1': 702, 'Rowe0': 883, 'Thomson0': 834, 'McCarthy0': 7, 'Panula5': 50, 'West3': 58, 'Kallio0': 374, 'Hoyt1': 206, 'Hoyt0': 638, 'Mannion0': 589, 'Touma2': 232, 'Futrelle1': 4, 'Jardin0': 507, 'Rosenbaum0': 827, 'Lemore0': 437, 'Davies2': 460, 'Myles0': 703, 'Reynolds0': 835, 'Robert1': 630, 'Butt0': 451, 'Wick2': 286, 'Emanuel0': 628, 'Ibrahim Shawah0': 643, 'Carbines0': 175, 'McEvoy0': 583, 'Moutal0': 75, 'Loring0': 875, 'Giles0': 896, 'Ling0': 157, 'Watson0': 552, 'Lahoud0': 443, 'Sedgwick0': 302, 'Assaf0': 711, 'Storey0': 799, 'Beesley0': 22, 'Sheerlinck0': 79, 'Hunt0': 218, 'Duquemin0': 800, 'Clifford0': 408, 'Stranden0': 602, 'Ahlin1': 40, 'Woolner0': 55, 'Caram1': 482, 'Sandstrom2': 11, 'Nakid2': 333, 'Frost0': 412, 'Moen0': 73, 'Henry0': 239, 'Persson1': 241, 'Mudd0': 671, 'Glynn0': 32, 'Bowerman1': 312, 'Douglas2': 816, 'Daniel0': 505, 'Nysten0': 132, 'Saalfeld0': 270, 'Turcin0': 173, 'Nasser1': 10, 'Waelens0': 78, 'Khalil1': 753, 'Pokrnic0': 863, 'Homer0': 502, 'Graham1': 242, 'Graham0': 699, 'Brown0': 177, 'Dorking0': 256, 'Clark1': 851, 'Bing0': 72, 'Blank0': 191, 'Tornquist0': 245, 'Olsen1': 180, 'Olsen0': 144, 'Lane0': 815, 'Davison1': 304, 'Butler0': 544, 'Calderhead0': 575, 'Cor0': 530, 'Kalvik0': 534, 'Hagland1': 386, 'Boulos2': 131, 'Boulos0': 497, 'Niklasson0': 855, 'Leitch0': 496, 'Endres0': 581, 'Fleming0': 275, 'Natsch1': 247, 'Garfirth0': 614, 'MacKay0': 854, 'Blackwell0': 300, 'Thayer2': 461, 'Holm0': 657, 'Rekic0': 105, 'Allen0': 5, 'Hendekovic0': 282, 'Svensson0': 424, 'Montvila0': 698, 'Perreault0': 441, 'Francatelli0': 278, 'Gronnestad0': 621, 'Maisner0': 399, 'Radeff0': 537, 'Daly0': 432, 'Hiltunen2': 846, 'Conlon0': 921, 'Jarvis0': 488, 'Bowen0': 515, 'Holthen0': 770, 'Risien0': 453, 'Walker0': 436, 'Klaber0': 578, 'Wright0': 466, 'Artagaveytia0': 419, 'Navratil2': 138, 'Hays2': 658, 'Seward0': 383, 'Hays0': 279, 'Appleton2': 478, 'Fry0': 654, 'Romaine0': 171, 'de Messemaeker1': 469, 'Gustafsson0': 331, 'Gustafsson2': 101, 'Lulic0': 659, 'Beckwith2': 225, 'Sutton0': 516, 'Cunningham0': 355, 'Carver0': 780, 'Drapkin0': 790, 'Hocking0': 840, 'Behr0': 700, 'Cotterill0': 911, 'Rothschild1': 434, 'Stankovic0': 257, 'Abelson1': 277, 'Shaughnessy0': 727, 'Lobb1': 230, 'Shellard0': 423, 'Knight0': 593, 'Silverthorne0': 572, \"O'Leary0\": 535, 'Saundercock0': 13, 'Baxter1': 114, 'Elias0': 624, 'Nankoff0': 598, 'Mitkoff0': 533, 'Lines1': 677, 'Burns0': 298, \"O'Driscoll0\": 47, 'Beattie0': 778, 'Cumings1': 2, 'Culumovic0': 674, 'Thomas2': 769, 'Penasco y Castellana1': 276, 'Parkes0': 251, 'Duff Gordon1': 467, 'Sloper0': 24, 'Strom2': 228, 'Ringhini0': 327, 'Barah0': 616, 'Richards2': 350, 'Crease0': 67, 'Cavendish1': 600, 'Earnshaw1': 797, 'Hilliard0': 795, 'Stengel1': 766, 'Lamb0': 752, 'Bjornstrom-Steffansson0': 371, 'Masselmani0': 20, 'Moubarek2': 65, 'Turja0': 555, 'Goldsmith2': 154, 'Fahlstrom0': 210, 'Holverson1': 35, 'Herman3': 510, \"O'Donoghue0\": 756, 'Nenkoff0': 205, 'Nysveen0': 292, 'Eklund0': 617, 'Paulner0': 487, 'Whabee0': 895, 'Nilsson0': 284, 'Dick1': 563, 'Dantcheff0': 639, 'Swift0': 682, 'Humblen0': 570, 'Matinoff0': 798, 'McCormack0': 661, 'Duane0': 253, 'Ekstrom0': 121, 'Wiseman0': 366, 'Smith0': 160, 'Krekorian0': 881, 'Nourney0': 922, 'Abrahamsson0': 850, 'Saether0': 928, 'Marvin1': 604, 'Cleaver0': 576, 'Gill0': 683, 'Cameron0': 193, 'Augustsson0': 663, 'Petranec0': 97, 'Stahelin-Maeglin0': 523, 'McDermott0': 80, 'Wittevrongel0': 873, 'Dean3': 90, 'Laleff0': 691, 'Meyer0': 649, 'Meyer1': 34, 'Chaudanson0': 733, 'Johansson0': 100, 'Cacic0': 405, 'Minkoff0': 740, 'Ryerson4': 280, 'Becker3': 167, 'Murphy0': 824, 'Tobin0': 627, 'Murphy1': 219, 'Goldschmidt0': 93, 'Kink2': 68, 'Gilbert0': 917, 'Weisz1': 125, 'Hold1': 215, 'Lingane0': 821, 'Stanley0': 420, 'Doyle0': 748, 'Minahan2': 222, 'Toufik0': 450, 'Minahan1': 354, 'Olsvigen0': 559, 'Odahl0': 307, 'Coleff0': 435, 'Case0': 750, 'Vestrom0': 15, 'Brobeck0': 782, 'Hood0': 70, 'Yousseff0': 421, 'Evans0': 776, 'Mardirosian0': 869, 'Abrahim0': 706, 'Barton0': 109, 'Icard0': 61, 'Smiljanic0': 148, 'Harmer0': 634, 'Collett0': 826, 'Ford4': 84, 'Maioni0': 428, 'Abbing0': 675, 'Ford0': 870, 'Kink-Heilmann4': 918, 'Oreskovic0': 347, 'Sundman0': 356, 'Kink-Heilmann2': 168, 'Lehmann0': 339, 'Dennis0': 288, 'del Carlo1': 316, 'Najib0': 690, 'Ohman0': 465, 'McCoy2': 272, 'Osen0': 129, 'Pernot0': 166, 'Kent0': 415, 'Turpin1': 41, 'Zabour1': 108, 'Alexander0': 650, 'Palsson4': 8, 'Hogeboom1': 618, 'Keefe0': 404, 'Eustis1': 422, 'Marechal0': 669, 'White0': 879, 'Uruchurtu0': 30, 'Riordan0': 923, 'Downton0': 485, 'Ilmakangas1': 591, 'Corn0': 147, 'Maybery0': 817, 'Parrish1': 236, 'Jerwan0': 406, 'Aks1': 678, 'Lam0': 565, 'Slayter0': 290, 'Weir0': 567, 'Frolicher2': 454, 'Danbom2': 365, 'Alhomaki0': 670, 'Brown2': 548, 'Faunthorpe1': 53, 'Wilson0': 908, 'Givard0': 195, 'Leyson0': 213, 'Potter1': 692, 'Emir0': 26, 'Slocovski0': 85, 'Celotti0': 86, 'Rood0': 169, 'Betros0': 330, 'Spinner0': 785, 'Larsson0': 211, 'Goldsmith0': 723, 'Andreasson0': 88, 'Vande Walle0': 183, 'Zakarian0': 788, 'Morley0': 396, 'Trout0': 344, 'Jefferys2': 716, 'Lundstrom0': 893, 'Thorneycroft1': 372, 'Shorney0': 92, 'Attalah0': 111, 'Ward0': 235, 'Bowenur0': 783, 'Tucker0': 738, 'Yousif0': 310, 'Wiklund1': 325, 'Thorne0': 233, 'Warren0': 861, 'Warren1': 320, 'Milling0': 398, 'Delalic0': 828, 'Rommetvedt0': 545, 'Pickard0': 370, 'Torfa0': 812, 'Hassan0': 592, 'Heininen0': 655, 'Vendel0': 844, 'Miles0': 745, 'Bazzani0': 200, 'Plotcharsky0': 335, 'Lindell1': 503, 'Caldwell2': 76, 'Meanwell0': 474, 'Bystrom0': 684, 'Harrison0': 238, 'Goldenberg1': 388, 'Webber0': 117, 'Shelley1': 693, 'Mayne0': 577, 'Honkanen0': 198, 'Deacon0': 831, 'Karlsson0': 410, 'Ismay0': 909, 'Asplund0': 837, 'Calic0': 153, 'Eitemiller0': 538, 'Chapman0': 568, 'Asplund6': 25, 'Dulles0': 888, 'Peuchen0': 385, 'Cairns0': 244, 'Midtsjo0': 857, 'Bailey0': 611, 'Hanna0': 268, 'Garside0': 481, 'Mernagh0': 179, 'Staneff0': 74, 'Toomey0': 393, 'Howard1': 710, 'Canavan0': 425, 'Kennedy0': 781, 'Dakic0': 560, 'Bucknell0': 728, 'Foo0': 529, 'Pasic0': 666, 'Veal0': 819, 'Novel0': 57, 'Lemberopolous0': 673, 'Hocking4': 625, 'Aldworth0': 747, 'Moran1': 106, 'Abbott2': 252, 'Kvillner0': 377, 'Elias2': 309, 'Gracie0': 786, 'Doharr0': 476, 'Norman0': 472, 'Pearce0': 806, 'Braf0': 764, 'Leader0': 641, 'Smart0': 402, 'White1': 99, 'Gale1': 348, 'de Brito0': 890, 'Swane0': 773, 'Doling1': 95, 'Sap0': 720, 'Moor1': 607, 'Pedersen0': 758, 'Taussig2': 237, 'Pinsky0': 174, 'Mulvihill0': 739, 'Gallagher0': 573, 'Lockyer0': 901, 'Thomas0': 777, 'Markun0': 694, 'de Mulder0': 258, 'Kassem0': 444, 'Yrois0': 182, 'Lundin0': 802, 'Kantor1': 96, 'Sobey0': 126, 'Shutes0': 506, 'Brocklebank0': 509, 'Parker0': 866, 'Cherry0': 234, 'Dooley0': 701, 'Hedman0': 646, 'Madigan0': 181, 'Ovies y Rodriguez0': 742, 'Strilic0': 904, 'Parr0': 524, 'Campbell0': 401, 'Mullens0': 569, 'Maguire0': 889, 'Charters0': 363, 'Baimbrigge0': 822, 'Jonsson0': 477, 'Ostby1': 54, 'Brady0': 715, 'Wilhelms0': 551, 'Williams1': 145, 'Williams0': 18, 'Maenpaa0': 221, 'Stone0': 662, 'Birnbaum0': 761, 'Lennon1': 46, 'Olsson0': 254, 'Harknett0': 214, 'Horgan0': 508, 'Hart0': 353, 'Hart2': 283, 'Ilett0': 82, 'Hellstrom0': 810, 'Naughton0': 924, 'Baumann0': 156, 'Youseff0': 185, 'Reeves0': 240, 'Thomas1': 645, 'Jensen0': 527, 'Jensen1': 584, 'Cribb1': 150, 'Ross0': 486, 'Andersen-Jensen1': 176, 'Gilnagh0': 146, 'Moran0': 6, 'Coelho0': 123, 'Razi0': 679, 'Harbeck0': 910, 'Shine0': 775, 'Reuchlin0': 660, 'Kiernan1': 196, 'Partner0': 295, 'Jermyn0': 322, 'Salkjelsvik0': 103, 'Lahtinen2': 281, 'Drew2': 358, 'Hosono0': 260, 'Danoff0': 289, 'van Billiard2': 143, 'Bracken0': 203, 'Dintcheff0': 787, 'Coutts2': 305, 'Connors0': 113, 'Colbert0': 919, 'Jenkin0': 69, 'Hodges0': 586, 'Vovk0': 442, 'Omont0': 825, 'Backstrom1': 188, 'Devaney0': 44, 'Backstrom3': 83, 'Barbara1': 317, \"O'Connell0\": 520, 'Vande Velde0': 608, 'Reynaldo0': 380, 'Isham0': 163, 'Peruschitz0': 807, \"O'Brien0\": 463, \"O'Brien1\": 170, 'Giglio0': 130, 'Ponesell0': 644, 'Nicola-Yarred1': 39, 'Angle1': 439, 'Mellinger1': 246, 'Newell1': 197, 'Davidson3': 759, 'Lang0': 431, 'Davidson1': 549, 'Richard0': 127, 'Oxenham0': 868, 'Ball0': 293, 'Nasr0': 872, 'Schabert1': 779, 'Drazenoic0': 122, 'Robins1': 124, 'Richards5': 376, 'Chevre0': 726, 'Salander0': 852, 'Stanton0': 774, 'Nosworthy0': 51, 'Moore0': 116, 'Newsom2': 128, 'Sjoblom0': 635, 'Zimmerman0': 364, 'Kenyon1': 392, 'Fynney0': 21, 'Laroche3': 43, 'Renouf1': 409, 'Silvey1': 375, 'Riihivouri0': 905, 'Christy2': 484, 'Renouf3': 588, 'Pulbaum0': 730, 'Theobald0': 612, 'Mahon0': 833, 'Pekoniemi0': 112, 'Spector0': 926, 'Bateman0': 140, 'Spencer1': 31, 'Gibson1': 906, 'Allison3': 269, 'Cohen0': 186, 'Dimic0': 306, 'Karnes0': 849, 'Bourke2': 172, 'Farthing0': 447, 'Hamalainen2': 224, 'Karaic0': 504, 'Hyman0': 848, 'Pettersson0': 648, 'Landergren0': 328, 'Willey0': 532, 'Braund1': 1, 'Rosenshine0': 886, 'Slemen0': 652, 'Snyder1': 709, 'Jalsevac0': 390, 'Harder1': 324, 'Oliva y Ocana0': 927, 'Elsbury0': 494, 'Assam0': 885, 'Carrau0': 81, 'Dyker1': 757, 'Sutehall0': 697, 'Everett0': 839, 'Sawyer0': 554, 'Vander Planke1': 19, 'Peters0': 557, 'Vander Planke3': 794, 'Vander Planke2': 38, 'Dahlberg0': 695, 'Sharp0': 462, 'Sirota0': 667, 'McCaffry0': 864, 'Demetri0': 751, 'Barkworth0': 521, 'Buckley0': 771, 'Mack0': 623, 'Petersen0': 784, 'Sjostedt0': 212, 'Slabenoff0': 499, 'Dodge2': 382, 'Mineff0': 266, 'Lithman0': 811, 'Hocking3': 449, 'Hickman2': 115, 'Perkin0': 194, 'Sweet0': 841, 'Stewart0': 64, 'Giles1': 681, 'Lindblom0': 250, 'Meek0': 357, 'Morrow0': 470, 'Newell2': 539, 'Beavan0': 326, 'Balkic0': 688, 'van Melkebeke0': 687, 'Foreman0': 387, 'Hampe0': 378, 'Birkeland0': 351, 'Ware0': 903, 'Mockler0': 315, 'Millet0': 391, 'Peter2': 120, 'Yasbeck1': 512, 'Osman0': 642, 'Buss0': 337, 'Sunderland0': 202, 'Fillbrook0': 892, 'Candee0': 836, 'Lefebre4': 162, 'Bryhl1': 590, 'McGovern0': 314, 'Nye0': 66, 'Davis0': 525, 'Aubart0': 323, 'Spedden2': 287, 'Harris0': 201, 'Harris1': 62, 'McGough0': 433, 'Hewlett0': 16, 'Cann0': 37, 'Makinen0': 763, 'Mallet2': 656, 'Mock1': 717, 'Kirkland0': 517, 'Ridsdale0': 446, 'Connaghton0': 605, 'Stoytcheff0': 475, 'Ashby0': 915, 'Hippach1': 294, 'Dowdell0': 77, 'Klasen2': 161, 'Assaf Khalil0': 712, 'Rothes0': 613, 'Nancarrow0': 765, \"O'Connor0\": 394, 'Ivanoff0': 597, 'Clarke1': 367, 'Scanlan0': 403, 'Daniels0': 791, 'Troupiansky0': 595, 'Johansson Palmquist0': 768, 'Geiger0': 743, 'Reed0': 227, 'Rintamaki0': 492, 'Chambers1': 587, 'Malachard0': 876, 'Haas0': 265, 'Corey0': 737, 'Greenfield1': 94, 'Brandeis0': 808, 'Jansson0': 341, 'Crafton0': 796, 'McNeill0': 838, 'Gheorgheff0': 362, 'Lindstrom0': 847, 'Mitchell0': 550, 'Dibden0': 899, 'Bonnell0': 12, 'Murdlin0': 491, 'Lester0': 651, 'Van Impe2': 361, 'Simonius-Blumer0': 531, 'Torber0': 501, 'Linehan0': 843, 'Gillespie0': 585, 'Naidenoff0': 259, 'McNamee1': 601, 'de Pelsmaeker0': 255, 'Quick2': 429, 'Bentham0': 856, 'Byles0': 139, 'Salomon0': 820, 'Sage10': 149, 'Baccos0': 845, 'Frolicher-Stehli2': 489, 'Wirz0': 704, 'Peduzzi0': 389, 'Chibnall1': 155, 'Hakkarainen1': 133, 'Watt0': 151, 'Sirayanian0': 60, 'Leonard0': 165, 'Bissette0': 243, 'Adahl0': 319, 'LeRoy0': 452, 'Tomlin0': 653, 'Smith1': 729, 'Kimball1': 513, 'Gavey0': 511, 'Mionoff0': 102, 'Farrell0': 445, 'Goodwin7': 59, 'Strom1': 187, 'Ali0': 192, 'Funk0': 313, 'Van der hoef0': 158, 'Roebling0': 686, 'Stokes0': 898, 'Simmons0': 473, 'Asim0': 318, 'Rosblom2': 231, 'Willer0': 772, 'Saade0': 865, 'Lovell0': 209, 'Phillips0': 368, 'Phillips1': 818, 'Lyntakoff0': 859, 'Leinonen0': 526, 'Jones0': 708, 'Markoff0': 676, 'Levy0': 264, 'Frauenthal2': 540, 'Frauenthal1': 296, 'Rheims0': 871, 'Finoli0': 830, 'Wenzel0': 853, 'Baclini3': 384, 'Johannesen-Bratthammer0': 381, 'Jonkoff0': 609, 'Williams-Lambert0': 308, 'Serepeca0': 672, 'Cornell2': 746, 'Longley0': 518, \"O'Dwyer0\": 28, 'Enander0': 887, 'Chisholm0': 860, 'Kelly0': 271, 'Douglas1': 457, 'Crosby2': 455, 'Niskanen0': 345, 'Collander0': 301, 'Gee0': 397, 'Tikkanen0': 334, 'McKane0': 342, 'Molson0': 418, 'Bostandyeff0': 519, 'Ayoub0': 631, 'Rogers0': 45, 'Chip0': 668, 'Cook0': 546, 'Stead0': 229, 'Nesson0': 882, 'Peacock2': 804, 'Soholt0': 580, 'Moraweck0': 285, 'Rasmussen0': 823, 'Barry0': 754, 'Bidois0': 332, 'Taylor1': 547, 'Bradley0': 430, 'Fischer0': 561, 'Barber0': 262, 'Julian0': 900, 'Albimona0': 189, 'Hale0': 164, 'Flynn0': 369, 'Sadlier0': 338, 'Keane0': 274, 'Pallas y Castello0': 907, 'Young0': 291, 'Lindahl0': 223, 'Rugg0': 56, 'Johnston3': 633, 'Guest0': 760, 'Petterson1': 379, 'Pavlovic0': 440, 'Abelseth0': 732, 'Sivic0': 471, 'Hirvonen1': 411, 'Hirvonen2': 705, 'Allum0': 664, 'Tenglin0': 762, 'Head0': 832, 'Keeping0': 744, 'Straus1': 749, 'Harrington0': 500, 'Borebank0': 803, 'Beauchamp0': 792, 'Windelov0': 417, 'Lesurer0': 596, 'Pain0': 343, 'Lievens0': 622, 'Fox0': 303, 'Lewy0': 267, 'McMahon0': 118, 'Botsford0': 894, 'Greenberg0': 579, 'Heikkinen0': 3, 'Henriksson0': 925, 'Mangiavacchi0': 731, 'Louch1': 373, 'Chapman1': 495, 'Schmidt0': 789, 'Berriman0': 594, 'Franklin0': 722, 'Bjorklund0': 736, 'Moussa0': 321, 'Payne0': 916, 'Ware1': 867, 'Hee0': 721, 'Ryan0': 438, \"O'Keefe0\": 902, 'Roth0': 719, 'Madill1': 562, 'Duran y More1': 685, 'Foley0': 767, 'Bengtsson0': 152, 'Harper1': 52, 'Kilgannon0': 629, 'Badt0': 541, 'Salonen0': 448, 'Guggenheim0': 636, 'Widegren0': 349, 'Brewe0': 619, 'Sivola0': 159, 'Nirva0': 615, 'Rice5': 17, 'Andrews0': 647, 'Andrews1': 249, 'Collyer2': 216, 'Strandberg0': 407, 'Colley0': 542, 'Nicholson0': 458, 'Nieminen0': 741, 'Chaffee1': 89, 'Gaskell0': 637, 'McCrie0': 814, 'Wells2': 606, 'Leeni0': 464, 'Todoroff0': 29, 'Flegenheim0': 713, 'McCrae0': 735, 'Adams0': 346, 'Corbett0': 724, 'Hipkins0': 912, 'Pears1': 141, 'Sagesser0': 528, 'Carr0': 190, 'Ilieff0': 707, 'McGowan0': 23, 'Hansen0': 514, 'Hansen1': 574, 'Karun1': 564, 'Rush0': 479, 'Katavelas0': 718, 'Matthews0': 360, 'Laitinen0': 427, 'Kreuchen0': 884, 'Hagardon0': 880, 'Daher0': 714, 'Padro y Manent0': 459, 'Andrew0': 135, 'Vander Cruyssen0': 689, 'Jacobsohn1': 199, 'Lurette0': 178, 'Jacobsohn3': 498, 'Hegarty0': 536}\n"
     ]
    }
   ],
   "source": [
    "# First, we'll add titles to the test set.\n",
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "# We're adding the Dona title to the mapping, because it's in the test set, but not the training set\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "titanic_test[\"Title\"] = titles\n",
    "# Check the counts of each unique title.\n",
    "print(pd.value_counts(titanic_test[\"Title\"]))\n",
    "\n",
    "# Now, we add the family size column.\n",
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
    "\n",
    "print(family_id_mapping)\n",
    "family_ids = titanic_test.apply(get_family_id, axis=1)\n",
    "family_ids[titanic_test[\"FamilySize\"] < 3] = -1\n",
    "titanic_test[\"FamilyId\"] = family_ids\n",
    "titanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]],\n",
    "    [RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2), [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "\n",
    "predictions[predictions <= .5] = 0\n",
    "predictions[predictions > .5] = 1\n",
    "predictions = predictions.astype(int)\n",
    "full_predictions.append(predictions)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv(\"kagglea3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think there is a lot to explore even with just one algorithm. In the tutorial, we were just given the values for the arguments of the algorithms that will work for the data the best, given the size. It would be interesting to see how I would have tried to do that. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
